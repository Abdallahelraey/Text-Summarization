{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\AI\\\\NLP\\\\HandsOn\\\\Text Summarization'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AI\\NLP\\HandsOn\\Text Summarization\\textsummarizer-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-26 09:23:11,910: INFO: config: PyTorch version 2.5.1+cu121 available.]\n"
     ]
    }
   ],
   "source": [
    "from TextSummarizer.constants import *\n",
    "from TextSummarizer.utils.file_utils import *\n",
    "from TextSummarizer.utils.config_utils import *\n",
    "from TextSummarizer.utils.data_utils import *\n",
    "from TextSummarizer.config.configuration import ConfigurationManager\n",
    "from TextSummarizer.logging import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "from pymongo.errors import PyMongoError\n",
    "from typing import Dict, List, Optional\n",
    "from collections import defaultdict\n",
    "from datasets import load_from_disk, Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MongoDBHandler:\n",
    "    def __init__(self):\n",
    "        try:\n",
    "            logger.debug(\"Initializing MongoDBHandler.\")\n",
    "            self.data_transformation_config = ConfigurationManager()\n",
    "            self.root_dir = self.data_transformation_config.get_data_transformation_config().root_dir\n",
    "            self.data_path = os.path.join(self.root_dir, \"sampled_dataset\")\n",
    "            self.config = get_settings()\n",
    "            self.uri = self.config.MONGODB_CONNECTION_STRING\n",
    "            self.db_name = self.config.MONGODB_NAME\n",
    "            self.client = self.connect_to_mongodb()\n",
    "            self.db = self.client[self.db_name]\n",
    "            self.db_name = \"text_summarization_database\"\n",
    "            self.db_collection_name = \"database_splits\"\n",
    "            self.texts = self.db['texts']\n",
    "            self.summaries = self.db['summaries']\n",
    "            logger.info(\"MongoDBHandler initialized successfully.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during initialization: {e}\")\n",
    "            raise\n",
    "\n",
    "    def connect_to_mongodb(self):\n",
    "        try:\n",
    "            client = MongoClient(self.uri, server_api=ServerApi('1'))\n",
    "            client.admin.command('ping')\n",
    "            print(\"Pinged your deployment. Successfully connected to MongoDB!\")\n",
    "            return client\n",
    "        except PyMongoError as e:\n",
    "            print(f\"Failed to connect to MongoDB: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    def load_data_from_disk(self) -> Dataset:\n",
    "        try:\n",
    "            logger.debug(f\"Loading dataset from disk at path: {self.data_path}\")\n",
    "            dataset = load_from_disk(self.data_path)\n",
    "            logger.info(\"Dataset loaded successfully.\")\n",
    "            return dataset\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading dataset from disk: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _prepare_dataset_for_mongo(self,dataset):\n",
    "        \"\"\"Convert DatasetDict to a MongoDB-compatible format\"\"\"\n",
    "        mongo_data = []\n",
    "        \n",
    "        # Process each split in the dataset\n",
    "        for split_name, split_data in dataset.items():\n",
    "            # Convert the split data to a dictionary\n",
    "            split_dict = split_data.to_dict()\n",
    "            \n",
    "            # Restructure the data for MongoDB\n",
    "            # MongoDB documents should be row-based rather than column-based\n",
    "            num_examples = len(next(iter(split_dict.values())))\n",
    "            for i in range(num_examples):\n",
    "                document = {'split': split_name}\n",
    "                for feature_name, feature_values in split_dict.items():\n",
    "                    document[feature_name] = feature_values[i]\n",
    "                mongo_data.append(document)\n",
    "        \n",
    "        return mongo_data\n",
    "\n",
    "    def test_and_create_collection(self,data):\n",
    "        try:\n",
    "            db = self.client[self.db_name]\n",
    "            collection = db[self.db_collection_name]\n",
    "            \n",
    "            # Drop the collection if it exists\n",
    "            if self.db_collection_name in db.list_collection_names():\n",
    "                collection.drop()\n",
    "                print(f\"Dropped existing collection: {self.db_collection_name}\")\n",
    "\n",
    "            # Insert data into the collection\n",
    "            if data:\n",
    "                result = collection.insert_many(data)\n",
    "                print(f\"Inserted {len(result.inserted_ids)} documents into '{self.db_collection_name}' collection.\")\n",
    "    \n",
    "        except PyMongoError as e:\n",
    "            print(f\"Error working with the collection: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    def upload_dataset_to_mongo(self, dataset):\n",
    "        try:\n",
    "            # Prepare the dataset\n",
    "            mongo_data = self._prepare_dataset_for_mongo(dataset)\n",
    "            \n",
    "            # Use your existing function to create and populate the collection\n",
    "            self.test_and_create_collection(mongo_data)\n",
    "            \n",
    "            print(f\"Successfully uploaded dataset to MongoDB Atlas\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error uploading dataset to MongoDB: {e}\")\n",
    "            raise\n",
    "\n",
    "    def mongodb_to_datasetdict(self) -> DatasetDict:\n",
    "        \"\"\"\n",
    "        Retrieve all data from MongoDB and convert it back to a DatasetDict object.\n",
    "        \"\"\"\n",
    "        logger.info(\"Starting to retrieve and convert MongoDB data to DatasetDict\")\n",
    "        try:\n",
    "            # Get database and collection\n",
    "            db = self.client[self.db_name]\n",
    "            collection = db[self.db_collection_name]\n",
    "            logger.debug(f\"Connected to database '{self.db_name}' and collection '{self.db_collection_name}'\")\n",
    "            \n",
    "            # Retrieve all documents (excluding MongoDB _id field)\n",
    "            all_documents = list(collection.find({}, {'_id': 0}))\n",
    "            logger.info(f\"Retrieved {len(all_documents)} documents from MongoDB\")\n",
    "            \n",
    "            if not all_documents:\n",
    "                logger.error(\"No documents found in the collection\")\n",
    "                raise ValueError(\"No documents found in the collection\")\n",
    "                \n",
    "            # Group documents by split\n",
    "            split_data = defaultdict(list)\n",
    "            for doc in all_documents:\n",
    "                split_name = doc.pop('split', 'train')\n",
    "                split_data[split_name].append(doc)\n",
    "            logger.debug(f\"Grouped documents into {len(split_data)} splits: {list(split_data.keys())}\")\n",
    "            \n",
    "            # Convert to DatasetDict format\n",
    "            dataset_dict = {}\n",
    "            for split_name, documents in split_data.items():\n",
    "                # Convert list of documents to column format\n",
    "                features = defaultdict(list)\n",
    "                for doc in documents:\n",
    "                    for key, value in doc.items():\n",
    "                        features[key].append(value)\n",
    "                \n",
    "                # Create Dataset object for each split\n",
    "                dataset_dict[split_name] = Dataset.from_dict(features)\n",
    "                logger.debug(f\"Created Dataset for split '{split_name}' with {len(documents)} examples\")\n",
    "            \n",
    "            final_dataset = DatasetDict(dataset_dict)\n",
    "            logger.info(\"Successfully converted MongoDB data to DatasetDict\")\n",
    "            return final_dataset\n",
    "            \n",
    "        except PyMongoError as e:\n",
    "            logger.error(f\"MongoDB error: {str(e)}\", exc_info=True)\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error converting data to DatasetDict: {str(e)}\", exc_info=True)\n",
    "            raise\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def save_summary(self, text: str, summary: str, model_name: str) -> str:\n",
    "        try:\n",
    "            logger.debug(f\"Saving summary for text with model: {model_name}\")\n",
    "            doc = {\n",
    "                \"text\": text,\n",
    "                \"summary\": summary,\n",
    "                \"model\": model_name,\n",
    "                \"created_at\": datetime.now()\n",
    "            }\n",
    "            result = self.summaries.insert_one(doc)\n",
    "            logger.info(f\"Summary saved with ID: {result.inserted_id}\")\n",
    "            return str(result.inserted_id)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving summary: {e}\")\n",
    "            raise\n",
    "\n",
    "    def get_summary(self, text_id: str) -> Dict:\n",
    "        try:\n",
    "            logger.debug(f\"Fetching summary with ID: {text_id}\")\n",
    "            summary = self.summaries.find_one({\"_id\": text_id})\n",
    "            logger.info(f\"Summary fetched: {summary}\")\n",
    "            return summary\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fetching summary: {e}\")\n",
    "            raise\n",
    "\n",
    "    def get_summaries_by_model(self, model_name: str) -> List[Dict]:\n",
    "        try:\n",
    "            logger.debug(f\"Fetching summaries for model: {model_name}\")\n",
    "            summaries = list(self.summaries.find({\"model\": model_name}))\n",
    "            logger.info(f\"Fetched {len(summaries)} summaries for model: {model_name}\")\n",
    "            return summaries\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fetching summaries by model: {e}\")\n",
    "            raise\n",
    "\n",
    "    def close(self):\n",
    "        try:\n",
    "            logger.debug(\"Closing MongoDB connection.\")\n",
    "            self.client.close()\n",
    "            logger.info(\"MongoDB connection closed.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error closing MongoDB connection: {e}\")\n",
    "            raise\n",
    "\n",
    "    def __enter__(self):\n",
    "        logger.debug(\"Entering MongoDBHandler context.\")\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        logger.debug(\"Exiting MongoDBHandler context.\")\n",
    "        self.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-26 09:59:42,179: INFO: config_utils: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-12-26 09:59:42,182: INFO: config_utils: yaml file: params.yaml loaded successfully]\n",
      "[2024-12-26 09:59:42,184: INFO: file_utils: created directory at: artifacts]\n",
      "[2024-12-26 09:59:42,185: INFO: file_utils: created directory at: artifacts/data_transformation]\n",
      "Pinged your deployment. Successfully connected to MongoDB!\n",
      "[2024-12-26 09:59:43,748: INFO: 1865962573: MongoDBHandler initialized successfully.]\n",
      "[2024-12-26 09:59:43,764: INFO: 1865962573: Dataset loaded successfully.]\n",
      "Dropped existing collection: database_splits\n",
      "Inserted 60 documents into 'database_splits' collection.\n",
      "Successfully uploaded dataset to MongoDB Atlas\n",
      "[2024-12-26 09:59:47,963: INFO: 1865962573: Starting to retrieve and convert MongoDB data to DatasetDict]\n",
      "[2024-12-26 09:59:49,336: INFO: 1865962573: Retrieved 60 documents from MongoDB]\n",
      "[2024-12-26 09:59:49,373: INFO: 1865962573: Successfully converted MongoDB data to DatasetDict]\n"
     ]
    }
   ],
   "source": [
    "mongodbhandler = MongoDBHandler()\n",
    "dataset = mongodbhandler.load_data_from_disk()\n",
    "mongodbhandler.upload_dataset_to_mongo(dataset)\n",
    "dataset = mongodbhandler.mongodb_to_datasetdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textsummarizer-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
